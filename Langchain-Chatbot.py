# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

pip install requests beautifulsoup4

import requests
from bs4 import BeautifulSoup

def load_data_from_url(url):
    try:
        # Fetch the page content
        response = requests.get(url)
        response.raise_for_status()  # Raise error for bad status codes

        # Parse the content
        soup = BeautifulSoup(response.text, 'html.parser')

        # Find all course elements (update the tag and class as per the website structure)
        courses = soup.find_all('h3', class_='course-title')  # Example tag/class

        # Extract course names
        course_list = [course.text.strip() for course in courses]

        return course_list if course_list else "No courses found."

    except Exception as e:
        return f"Error loading data: {e}"

# Usage
url = "https://brainlox.com/courses/category/technical"
data = load_data_from_url(url)
print(data)

pip install selenium

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service

def load_data_from_url(url):
    try:
        # Set up the Chrome WebDriver
        service = Service('/path/to/chromedriver')  # Replace with the path to your chromedriver
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')  # Run headless to avoid opening the browser

        driver = webdriver.Chrome(service=service, options=options)
        driver.get(url)

        # Wait for content to load if necessary
        driver.implicitly_wait(10)

        # Find course elements (adjust selectors as needed)
        courses = driver.find_elements(By.CSS_SELECTOR, '.card-title')  # Example class name

        # Extract text from the elements
        course_list = [course.text for course in courses]

        driver.quit()
        return course_list if course_list else "No courses found."

    except Exception as e:
        return f"Error loading data: {e}"

# Usage
url = "https://brainlox.com/courses/category/technical"
data = load_data_from_url(url)
print(data)

service = Service('C:/path-to-driver/chromedriver.exe')

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By

def load_data_from_url(url):
    try:
        # Set up the Selenium Chrome Driver
        service = Service("/path/to/chromedriver")  # Update path
        options = webdriver.ChromeOptions()
        options.add_argument("--headless")  # Runs Chrome in headless mode

        driver = webdriver.Chrome(service=service, options=options)
        driver.get(url)

        # Let the content load
        driver.implicitly_wait(10)

        # Select elements with course titles (inspect and verify class names)
        courses = driver.find_elements(By.CLASS_NAME, "card-title")

        # Extract and display course names
        course_list = [course.text.strip() for course in courses]

        driver.quit()
        return course_list if course_list else "No courses found."

    except Exception as e:
        return f"Error loading data: {e}"

# Usage
url = "https://brainlox.com/courses/category/technical"
data = load_data_from_url(url)
print("Courses Found:")
print("\n".join(data))

pip install langchain sentence-transformers faiss-cpu

pip install -U langchain-community

pip install langchain faiss-cpu sentence-transformers

from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings

def create_and_store_embeddings(data):
    # Initialize the embedding model
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

    # Create the FAISS vector store
    vector_store = FAISS.from_texts(data, embeddings)

    # Save the vector store for later use
    vector_store.save_local("vectorstore")
    print("Embeddings stored successfully!")

# Sample usage: Assuming `data` contains the list of course names
data = ["Course 1: Python Programming", "Course 2: Data Science Bootcamp"]  # Replace with your data
create_and_store_embeddings(data)

import faiss
from sentence_transformers import SentenceTransformer

def create_and_store_embeddings(data):
    # Load embedding model
    model = SentenceTransformer("all-MiniLM-L6-v2")

    # Generate embeddings
    embeddings = model.encode(data)

    # Initialize FAISS index
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)

    # Save FAISS index locally
    faiss.write_index(index, "vectorstore/index.faiss")
    print("Embeddings stored successfully!")

data = ["Python Programming Bootcamp", "Data Science with AI"]  # Replace with your data
create_and_store_embeddings(data)

pip install flask

pip install -U langchain-openai

from langchain_openai import OpenAIEmbeddings

import os
os.environ["OPENAI_API_KEY"] = "your_openai_api_key"

!pip install flask flask-ngrok

!pip install pyngrok

from pyngrok import ngrok

# Replace 'your_ngrok_authtoken' with the token from your ngrok account
ngrok.set_auth_token("2sHqgvcHnhcDwohJzl1xHSeWILw_6XgXxAnMPKNXakE3yVW6B")

# Create an ngrok tunnel
public_url = ngrok.connect(5000)
print(f"Public URL: {public_url}")

!curl -X POST https://ca2f-35-247-1-243.ngrok-free.app/chat \
     -H "Content-Type: application/json" \
     -d '{"message": "Hello"}'

from flask import Flask, request, jsonify
from pyngrok import ngrok

app = Flask(__name__)

# Authenticate with ngrok using your authtoken
ngrok.set_auth_token("2sHqgvcHnhcDwohJzl1xHSeWILw_6XgXxAnMPKNXakE3yVW6B")

# Create an ngrok tunnel
public_url = ngrok.connect(5000)
print(f"Public URL: {public_url}")

@app.route('/chat', methods=['POST'])
def chat():
    user_input = request.json.get("message", "")
    if not user_input:
        return jsonify({"error": "No input provided"}), 400
    response = {"response": f"You said: {user_input}"}
    return jsonify(response)

if __name__ == "__main__":
    app.run(port=5000)

